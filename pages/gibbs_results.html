<html>

<head>
	<link rel="stylesheet" type="text/css" href="../css/gibbsStyle.css">
</head>

<body>

<ol id="b_results">

<li class="b_algo"><h2><a href="http://en.wikipedia.org/wiki/Gibbs_sampling" h="ID=SERP,5117.1"><strong>Gibbs sampling</strong> - <strong>Wikipedia</strong>, the free encyclopedia</a></h2><div class="b_attribution" u="0|5054|5016351337349756|jamGml089A7pLDbd8LYCFYqZIkzzMAKb"><cite><strong>en.wikipedia.org</strong>/wiki/<strong>Gibbs_sampling</strong></cite><a aria-haspopup="1" aria-label="Actions for this site" href="#"><span class="c_tlbxTrg"><span class="c_tlbxTrgIcn sw_ddgn"></span><span class="c_tlbxH" h="BASE:CACHEDPAGEDEFAULT" k="SERP,5118.1"></span></span></a></div><div class="b_caption"><div class="b_snippet"><p>In statistics and in statistical physics, <strong>Gibbs sampling</strong> or a <strong>Gibbs</strong> <strong>sampler</strong> is a <strong>Markov chain</strong> <strong>Monte Carlo</strong> (MCMC) algorithm for obtaining a sequence of observations ...</p></div><ul class="b_factrow"><li><a href="http://en.wikipedia.org/wiki/Gibbs_sampling#Introduction" h="ID=SERP,5110.1">Introduction</a> </li><li><a href="http://en.wikipedia.org/wiki/Gibbs_sampling#Implementation" h="ID=SERP,5111.1">Implementation</a> </li><li><a href="http://en.wikipedia.org/wiki/Gibbs_sampling#Inference" h="ID=SERP,5112.1">Inference</a>  </li><li><a href="http://en.wikipedia.org/wiki/Gibbs_sampling#Mathematical_background" h="ID=SERP,5113.1">Mathematical background</a></li></ul></div></li>
<br>
<li class="b_algo"><div class="b_title"><span class="sb_doct_txt b_float">[PDF]</span><h2><a href="http://web.mit.edu/%7Ewingated/www/introductions/mcmc-gibbs-intro.pdf" h="ID=SERP,5128.1"><strong>Markov Chain</strong> <strong>Monte Carlo</strong> and <strong>Gibbs Sampling</strong></a></h2></div><div class="b_caption"><div class="b_attribution"><cite><strong>web.mit.edu</strong>/~wingated/www/introductions/mcmc-<strong>gibbs</strong>-intro.pdf</cite></div><p>4 MCMC AND <strong>GIBBS SAMPLING</strong>
 The probability that the chain has state value s i at time (or step) 
t+1is given by the Chapman-Kolomogrov equation, which sums over the ...</p></div></li>
<br>
<li class="b_algo"><h2><a href="http://cs.brown.edu/research/ai/dynamics/tutorial/Documents/GibbsSampling.html" h="ID=SERP,5139.1"><strong>Gibbs Sampling</strong> - Brown University</a></h2><div class="b_caption"><div class="b_attribution" u="2|5056|4809342556638911|LPu8zqY1pRKLCVJB8aimt4AuoXE4cw9P"><cite>cs.brown.edu/research/ai/dynamics/tutorial/Documents/<strong>GibbsSampling</strong>...</cite><a aria-haspopup="1" aria-label="Actions for this site" href="#"><span class="c_tlbxTrg"><span class="c_tlbxTrgIcn sw_ddgn"></span><span class="c_tlbxH" h="BASE:CACHEDPAGEDEFAULT" k="SERP,5140.1"></span></span></a></div><p>In this section, we describe <strong>Gibbs sampling</strong>, a general method for probabilistic inference. <strong>Gibbs sampling</strong> is well suited to coping with incomplete information and is ...</p></div></li>
<br>
<li class="b_algo"><h2><a href="http://www.ehow.com/list_7851911_gibbs-sampling-methods.html" h="ID=SERP,5156.1"><strong>Gibbs Sampling</strong> Methods | <strong>eHow</strong></a></h2><div class="b_caption"><div class="b_attribution" u="3|5057|5050260124008931|sN_dQ1JciZf4l6o-W0CQMveL1PDY2nq-"><cite class="sb_crmb"><span><strong>www.ehow.com</strong> </span><span> </span><span><a href="http://www.ehow.com/hobbies-games/science-nature/" h="ID=SERP,5149.1">Science &amp; Nature</a> </span><span><a href="http://www.ehow.com/hobbies-games/science-nature/science/" h="ID=SERP,5150.1">Science</a></span></cite><a aria-haspopup="1" aria-label="Actions for this site" href="#"><span class="c_tlbxTrg"><span class="c_tlbxTrgIcn sw_ddgn"></span><span class="c_tlbxH" h="BASE:CACHEDPAGEDEFAULT" k="SERP,5157.1"></span></span></a></div><p><strong>Gibbs sampling</strong>
 is a method used to deal with probabilistic inference. It is frequently
 used for data sets that are incomplete. Traditional statistical 
inference uses ...</p></div></li>
<br>
<li class="b_algo"><h2><a href="http://research.microsoft.com/en-us/um/cambridge/projects/infernet/docs/gibbs%20sampling.aspx" h="ID=SERP,5168.1">Infer.NET</a></h2><div class="b_caption"><div class="b_attribution" u="4|5058|4774510384517688|7m7l0cxpJuZ7MmGF-KU2X1To-D28UHgm"><cite><strong>research.microsoft.com</strong>/.../infernet/docs/<strong>gibbs</strong>%20<strong>sampling</strong>.aspx</cite><a aria-haspopup="1" aria-label="Actions for this site" href="#"><span class="c_tlbxTrg"><span class="c_tlbxTrgIcn sw_ddgn"></span><span class="c_tlbxH" h="BASE:CACHEDPAGEDEFAULT" k="SERP,5169.1"></span></span></a></div><p>A more efficient version of <strong>Gibbs sampling</strong>, especially in the case of deterministic constraints, is the block <strong>Gibbs</strong> <strong>sampler</strong>. Here the variables are grouped into ...</p></div></li>

</ol>

</body>

</html>